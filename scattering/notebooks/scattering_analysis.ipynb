{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FRB Scattering Analysis\n",
    "\n",
    "**Production notebook for MCMC scattering analysis**\n",
    "\n",
    "Workflow:\n",
    "1. Load configuration and create pipeline\n",
    "2. (Optional) Refine initial guess interactively\n",
    "3. Run MCMC fitting\n",
    "4. Generate diagnostic plots and corner plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Imports and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Imports successful\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import yaml\n",
    "import numpy as np\n",
    "\n",
    "# Add paths - go up to FLITS root\n",
    "FLITS_ROOT = Path.cwd().parent.parent\n",
    "sys.path.insert(0, str(FLITS_ROOT))\n",
    "sys.path.insert(0, str(FLITS_ROOT / 'scattering'))\n",
    "os.chdir(FLITS_ROOT)  # Change to project root for relative paths in configs\n",
    "\n",
    "from scat_analysis.burstfit_pipeline import BurstPipeline\n",
    "from scat_analysis.burstfit_interactive import InitialGuessWidget\n",
    "from scat_analysis.config_utils import load_config\n",
    "\n",
    "print(f'[OK] Imports successful')\n",
    "print(f'[OK] Working directory: {Path.cwd()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Configuration\n",
    "\n",
    "**Select your burst configuration file:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Loaded config: /Users/jakobfaber/Documents/research/caltech/ovro/dsa110/FLITS/scattering/configs/bursts/chime/casey_chime.yaml\n",
      "    Burst: casey\n",
      "    Telescope: chime\n"
     ]
    }
   ],
   "source": [
    "# Configuration file path - use relative path from FLITS root\n",
    "config_file = 'scattering/configs/bursts/chime/casey_chime.yaml'\n",
    "# Alternative: DSA data\n",
    "# config_file = 'scattering/configs/bursts/dsa/casey_dsa.yaml'\n",
    "\n",
    "# Load configuration using the unified config loader\n",
    "config = load_config(config_file)\n",
    "\n",
    "print(f'[OK] Loaded config: {config_file}')\n",
    "print(f'    Data path: {config.path}')\n",
    "print(f'    Telescope: {config.telescope.name}')\n",
    "print(f'    DM init: {config.dm_init}')\n",
    "print(f'    Downsampling: {config.pipeline.f_factor}x freq, {config.pipeline.t_factor}x time')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Create Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "BurstPipeline.__init__() missing 3 required positional arguments: 'inpath', 'outpath', and 'name'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Create pipeline instance\u001b[39;00m\n\u001b[32m      2\u001b[39m pipeline_params = {\n\u001b[32m      3\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mtelescope_cfg\u001b[39m\u001b[33m'\u001b[39m: telescope_cfg,\n\u001b[32m      4\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mburst_cfg\u001b[39m\u001b[33m'\u001b[39m: config_file,\n\u001b[32m      5\u001b[39m     \u001b[33m'\u001b[39m\u001b[33moutput_dir\u001b[39m\u001b[33m'\u001b[39m: config.get(\u001b[33m'\u001b[39m\u001b[33moutput_dir\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33m./output\u001b[39m\u001b[33m'\u001b[39m),\n\u001b[32m      6\u001b[39m }\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m pipe = \u001b[43mBurstPipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mpipeline_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m'\u001b[39m\u001b[33m[OK] Pipeline created\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[31mTypeError\u001b[39m: BurstPipeline.__init__() missing 3 required positional arguments: 'inpath', 'outpath', and 'name'"
     ]
    }
   ],
   "source": [
    "# Create pipeline instance with the new API\n",
    "pipe = BurstPipeline(\n",
    "    inpath=config.path,\n",
    "    outpath=config.path.parent,  # Output to same directory as data\n",
    "    name=config.path.stem.split('_')[0],  # Extract burst name from filename\n",
    "    dm_init=config.dm_init,\n",
    "    telescope=config.telescope,\n",
    "    sampler=config.sampler,\n",
    "    f_factor=config.pipeline.f_factor,\n",
    "    t_factor=config.pipeline.t_factor,\n",
    "    steps=config.pipeline.steps,\n",
    "    nproc=4,  # Use 4 cores for notebook (adjust as needed)\n",
    ")\n",
    "\n",
    "# Manually create the dataset now (normally happens inside run_full())\n",
    "# This is needed so we can use the interactive widget before MCMC\n",
    "from scat_analysis.burstfit_pipeline import BurstDataset\n",
    "pipe.dataset = BurstDataset(\n",
    "    inpath=pipe.inpath,\n",
    "    outpath=pipe.outpath,\n",
    "    name=pipe.name,\n",
    "    telescope=config.telescope,\n",
    "    sampler=config.sampler,\n",
    "    f_factor=config.pipeline.f_factor,\n",
    "    t_factor=config.pipeline.t_factor,\n",
    ")\n",
    "# Set dm_init on both the dataset and its model (widget looks for dataset.dm_init)\n",
    "pipe.dataset.dm_init = pipe.dm_init\n",
    "pipe.dataset.model.dm_init = pipe.dm_init\n",
    "\n",
    "print('[OK] Pipeline created')\n",
    "print(f'    Data shape after downsampling: {pipe.dataset.data.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Interactive Initial Guess Refinement (Optional)\n",
    "\n",
    "Use the widget to visually refine initial parameters before MCMC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create interactive widget for initial guess refinement\n",
    "# The widget displays Data vs Model with real-time slider adjustments\n",
    "\n",
    "guess_widget = InitialGuessWidget(\n",
    "    dataset=pipe.dataset,  # BurstDataset object with .data, .time, .freq, .df_MHz\n",
    "    model_key=\"M3\",        # Use full model with all parameters\n",
    ")\n",
    "\n",
    "# Display widget (in Jupyter)\n",
    "# Adjust sliders to match data, click \"Auto-Optimize\", then \"Accept & Continue\"\n",
    "display(guess_widget.create_widget())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply refined initial guess to pipeline (after using the widget above)\n",
    "# If you used the widget, this retrieves the optimized parameters\n",
    "# If not, it uses the automatic data-driven guess\n",
    "\n",
    "refined_params = guess_widget.get_params()\n",
    "pipe.seed_single = refined_params\n",
    "\n",
    "print('[OK] Applied initial guess to pipeline')\n",
    "print(f'    c0: {refined_params.c0:.4f}')\n",
    "print(f'    t0: {refined_params.t0:.4f} ms')\n",
    "print(f'    gamma: {refined_params.gamma:.4f}')\n",
    "print(f'    zeta: {refined_params.zeta:.4f}')\n",
    "print(f'    tau_1ghz: {refined_params.tau_1ghz:.4f} ms')\n",
    "print(f'    alpha: {refined_params.alpha:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Run MCMC Fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run full pipeline\n",
    "# Options:\n",
    "#   model_scan=True  -> Compare M0, M1, M2, M3 models via BIC\n",
    "#   model_scan=False -> Fit M3 (full model) directly\n",
    "#   diagnostics=True -> Run post-fit diagnostics (sub-band consistency, etc.)\n",
    "#   plot=True        -> Generate diagnostic plots\n",
    "\n",
    "results = pipe.run_full(\n",
    "    model_scan=True,     # Run model selection\n",
    "    diagnostics=False,   # Skip diagnostics for speed (enable for full analysis)\n",
    "    plot=True,           # Generate plots\n",
    "    show=True,           # Display plots inline\n",
    ")\n",
    "\n",
    "print('[OK] MCMC fitting complete')\n",
    "print(f'    Best model: {results[\"best_key\"]}')\n",
    "print(f'    χ²/dof: {results[\"goodness_of_fit\"][\"chi2_reduced\"]:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Post-Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract results\n",
    "sampler = results.get('sampler')\n",
    "best_params = results.get('best_params')\n",
    "param_names = list(results.get('param_names', []))\n",
    "flat_chain = results.get('flat_chain')\n",
    "\n",
    "# Check convergence\n",
    "if sampler is not None:\n",
    "    try:\n",
    "        tau = sampler.get_autocorr_time(quiet=True)\n",
    "        print(f'Autocorrelation times: {tau}')\n",
    "        print(f'Effective samples: {flat_chain.shape[0]}')\n",
    "    except Exception as e:\n",
    "        print(f'[~] Could not compute autocorrelation: {e}')\n",
    "\n",
    "# Print best-fit parameters with uncertainties\n",
    "print('\\nBest-fit parameters (median ± 1σ):')\n",
    "if flat_chain is not None and len(param_names) > 0:\n",
    "    for i, name in enumerate(param_names):\n",
    "        median = np.median(flat_chain[:, i])\n",
    "        std = np.std(flat_chain[:, i])\n",
    "        print(f'  {name}: {median:.4f} ± {std:.4f}')\n",
    "elif best_params is not None:\n",
    "    from dataclasses import asdict\n",
    "    for name, val in asdict(best_params).items():\n",
    "        print(f'  {name}: {val:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate corner plot\n",
    "from scat_analysis.burstfit_corner import make_beautiful_corner, get_clean_samples\n",
    "\n",
    "# Get clean samples (with burn-in removed)\n",
    "clean_samples = get_clean_samples(sampler, param_names, verbose=True)\n",
    "\n",
    "# Create corner plot\n",
    "fig = make_beautiful_corner(\n",
    "    clean_samples, \n",
    "    param_names, \n",
    "    best_params=best_params,\n",
    "    title=f'Posterior: {results[\"best_key\"]} ({clean_samples.shape[0]} samples)'\n",
    ")\n",
    "\n",
    "# Save\n",
    "output_dir = config.path.parent\n",
    "corner_path = output_dir / f'{config.path.stem}_corner.png'\n",
    "fig.savefig(corner_path, dpi=150, bbox_inches='tight')\n",
    "print(f'[OK] Corner plot saved to {corner_path}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis Complete\n",
    "\n",
    "### Output Files\n",
    "- Diagnostic plots: `{output_dir}/*.png`\n",
    "- MCMC chains: `{output_dir}/chains.npy`\n",
    "- Corner plot: `{output_dir}/corner_plot.png`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
